{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25cddd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 1234) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98f7661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal values\n",
    "\n",
    "adam_epochs = 45000\n",
    "adam_lr = 1e-3\n",
    "lbfgs_epochs = 50000\n",
    "L = 7.25*1e-4\n",
    "RL = 0.314\n",
    "C = 1.645 *1e-4\n",
    "RC = 2.01 * 1e-1\n",
    "Rdson = 0.221\n",
    "Rload1 = 3.1\n",
    "Rload2 = 10.2\n",
    "Rload3 = 6.1\n",
    "Vin = 48\n",
    "VF = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c5e35",
   "metadata": {},
   "source": [
    "## Let's Test The Accuracy of dt of Runge-Kutta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b13324ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without sub-steps:\n",
      "i1_pred = 8.805077, i1 = 8.805084, Delta_i = -6.498587e-06\n",
      "v1_pred = 26.041748, v1 = 26.041720, Delta_v = 2.817933e-05\n",
      "With 1000 sub-steps:\n",
      "i1_pred = 8.805077, i1 = 8.805084, Delta_i = -6.574731e-06\n",
      "v1_pred = 26.041749, v1 = 26.041720, Delta_v = 2.886677e-05\n"
     ]
    }
   ],
   "source": [
    "def predict_next_state(\n",
    "    i0: float,\n",
    "    v0: float,\n",
    "    D: float,\n",
    "    dt: float,\n",
    "    L: float,\n",
    "    RL: float,\n",
    "    C: float,\n",
    "    RC: float,\n",
    "    Rdson: float,\n",
    "    Rload: float,\n",
    "    Vin: float,\n",
    "    Vf: float,\n",
    "    n_substeps: int = 100,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Predict next state using RK4 with optional sub-stepping.\"\"\"\n",
    "    h = dt / n_substeps  # smaller time step\n",
    "    i, v = i0, v0\n",
    "\n",
    "    def f(i, v):\n",
    "        di = (-(RL + Rdson * D) * i - v + D * Vin - (1 - D) * Vf) / L\n",
    "        dv = (Rload * i - v + C * RC * Rload * di) / (C * (RC + Rload))\n",
    "        return di, dv\n",
    "\n",
    "    for _ in range(n_substeps):\n",
    "        k1_i, k1_v = f(i, v)\n",
    "        k2_i, k2_v = f(i + 0.5 * h * k1_i, v + 0.5 * h * k1_v)\n",
    "        k3_i, k3_v = f(i + 0.5 * h * k2_i, v + 0.5 * h * k2_v)\n",
    "        k4_i, k4_v = f(i + h * k3_i, v + h * k3_v)\n",
    "\n",
    "        i += (h / 6) * (k1_i + 2 * k2_i + 2 * k3_i + k4_i)\n",
    "        v += (h / 6) * (k1_v + 2 * k2_v + 2 * k3_v + k4_v)\n",
    "\n",
    "    return i, v\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from h5_auxiliaries.datatransients import TransientData\n",
    "\n",
    "# Load data\n",
    "db_dir = Path(r\"C:\\Users\\JC28LS\\OneDrive - Aalborg Universitet\\Desktop\\Work\\Databases\")\n",
    "db_name = \"buck_converter_Shuai_processed.h5\"\n",
    "tr1 = TransientData.from_h5(db_dir / db_name, \"ideal\", 1)\n",
    "\n",
    "# Index to test\n",
    "idx = 51\n",
    "i0 = tr1.i[idx]\n",
    "v0 = tr1.v[idx]\n",
    "i1 = tr1.i[idx + 1]\n",
    "v1 = tr1.v[idx + 1]\n",
    "D = tr1.D[idx]\n",
    "dt = tr1.dt[idx]\n",
    "\n",
    "# Nominal parameters\n",
    "i1_pred_ssteps, v1_pred_ssteps = predict_next_state(\n",
    "    i0=i0,\n",
    "    v0=v0,\n",
    "    D=D,\n",
    "    dt=dt,\n",
    "    L=7.25e-4,\n",
    "    RL=0.314,\n",
    "    C=1.645e-4,\n",
    "    RC=0.201,\n",
    "    Rdson=0.221,\n",
    "    Rload=3.1,\n",
    "    Vin=48.0,\n",
    "    Vf=1.0,\n",
    "    n_substeps=1000,\n",
    ")\n",
    "\n",
    "# Predict without sub-steps\n",
    "i1_pred, v1_pred = predict_next_state(\n",
    "    i0=i0,\n",
    "    v0=v0,\n",
    "    D=D,\n",
    "    dt=dt,\n",
    "    L=L,\n",
    "    RL=RL,\n",
    "    C=C,\n",
    "    RC=RC,\n",
    "    Rdson=Rdson,\n",
    "    Rload=Rload1,  # Using Rload1 as an example\n",
    "    Vin=Vin,\n",
    "    Vf=VF,\n",
    "    n_substeps=1,  # No sub-steps\n",
    ")\n",
    "\n",
    "print(\"Without sub-steps:\")\n",
    "print(f\"i1_pred = {i1_pred:.6f}, i1 = {i1:.6f}, Delta_i = {i1_pred - i1:.6e}\")\n",
    "print(f\"v1_pred = {v1_pred:.6f}, v1 = {v1:.6f}, Delta_v = {v1_pred - v1:.6e}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"With 1000 sub-steps:\")\n",
    "print(f\"i1_pred = {i1_pred_ssteps:.6f}, i1 = {i1:.6f}, Delta_i = {i1_pred_ssteps - i1:.6e}\")\n",
    "print(f\"v1_pred = {v1_pred_ssteps:.6f}, v1 = {v1:.6f}, Delta_v = {v1_pred_ssteps - v1:.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d838bcb",
   "metadata": {},
   "source": [
    "**There is virtually no difference in the prediction error!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92258ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the datasets\n",
    "from h5_auxiliaries.datatransients import TransientData\n",
    "\n",
    "db_dir = Path(r\"C:\\Users\\JC28LS\\OneDrive - Aalborg Universitet\\Desktop\\Work\\Databases\")\n",
    "db_name = \"buck_converter_Shuai_processed.h5\"\n",
    "\n",
    "tr1 = TransientData.from_h5(db_dir / db_name, \"ideal\", 1)\n",
    "\n",
    "i_n = tr1.i[:-1]\n",
    "v_n = tr1.v[:-1]\n",
    "i_np1 = tr1.i[1:]\n",
    "v_np1 = tr1.v[1:]\n",
    "D = tr1.D[:-1]\n",
    "dt = tr1.dt[:-1]\n",
    "\n",
    "\n",
    "X = np.stack([i_n, v_n, i_np1, v_np1, D, dt], axis=1)\n",
    "\n",
    "class Normalizer:\n",
    "    \"\"\"Normalizer for the input data.\"\"\"\n",
    "    def __init__(self, X: np.ndarray):\n",
    "        i_mean, i_std, v_mean, v_std, dt_mean, dt_std = self._get_means(X)\n",
    "        # add dummy values for D\n",
    "        self.mean = np.array([i_mean, v_mean, i_mean, v_mean, 0.0, dt_mean])\n",
    "        self.std = np.array([i_std, v_std, i_std, v_std, 1, dt_std])\n",
    "        \n",
    "    \n",
    "    def _get_means(self, X: np.ndarray) -> Tuple[float, float, float, float]:\n",
    "        # i_all is i_n with concatenated the LAST VALUE of i_np1\n",
    "        i_n_last = X[:, 0]  # i_n\n",
    "        i_np1_last = X[-1, 2]\n",
    "        i_all = np.concatenate((i_n_last, [i_np1_last]), axis=0)\n",
    "        i_mean = i_all.mean()\n",
    "        i_std = i_all.std()\n",
    "        \n",
    "        # v_all is v_n with concatenated the LAST VALUE of v_np1\n",
    "        v_n_last = X[:, 1]\n",
    "        v_np1_last = X[-1, 3]\n",
    "        v_all = np.concatenate((v_n_last, [v_np1_last]), axis=0)\n",
    "        v_mean = v_all.mean()\n",
    "        v_std = v_all.std()\n",
    "        \n",
    "        dt_mean = X[:, 5].mean()\n",
    "        dt_std = X[:, 5].std()\n",
    "        return i_mean, i_std, v_mean, v_std, dt_mean, dt_std\n",
    "\n",
    "\n",
    "    def normalize(self, X: np.ndarray) -> np.ndarray:\n",
    "        # Normalize the input data X using the mean and std\n",
    "        X_norm = (X - self.mean) / self.std\n",
    "        return X_norm\n",
    "    \n",
    "    def denormalize(self, X_norm: np.ndarray) -> np.ndarray:\n",
    "        # Denormalize the input data X_norm using the mean and std\n",
    "        X_denorm = X_norm * self.std + self.mean\n",
    "        return X_denorm\n",
    "        \n",
    "normalizer = Normalizer(X)\n",
    "X_norm = normalizer.normalize(X)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3051f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create simple feedforward neural network that estimates parameters\n",
    "class ParamEstimator(nn.Module):\n",
    "    \"\"\"Predicts physical parameters [L, RL, C, RC, Rdson, Rload, Vin, Vf] from a single sample.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim: int, hidden_layers: List[int]):\n",
    "        super().__init__()\n",
    "        dims = [input_dim] + hidden_layers + [8]\n",
    "        layers: List[nn.Module] = []\n",
    "        for in_dim, out_dim in zip(dims[:-1], dims[1:]):\n",
    "            layers.append(nn.Linear(in_dim, out_dim))\n",
    "            # last layer linear, others tanh\n",
    "            if out_dim != 8:\n",
    "                layers.append(nn.Tanh())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: [i_n, v_n, i_np1, v_np1, D, dt]\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def denorm_physical_params(\n",
    "    L: torch.Tensor,\n",
    "    RL: torch.Tensor,\n",
    "    C: torch.Tensor,\n",
    "    RC: torch.Tensor,\n",
    "    Rdson: torch.Tensor,\n",
    "    Rload: torch.Tensor,\n",
    "    Vin: torch.Tensor,\n",
    "    Vf: torch.Tensor,\n",
    ") -> Tuple[\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Denormalize the physical parameters from their logarithmic form.\n",
    "    The parameters are expected to be in the logarithmic scale.\n",
    "    \"\"\"\n",
    "    L = torch.exp(L) * 1e-6  # assume the network gets the uH value\n",
    "    RL = torch.exp(RL)\n",
    "    C = torch.exp(C) * 1e-6  # assume the network gets the uF value\n",
    "    RC = torch.exp(RC)\n",
    "    Rdson = torch.exp(Rdson) * 1e-3  # the Rdson is quite small, so we assume it is in mOhm\n",
    "    Rload = torch.exp(Rload)*10  # Rload is in Ohm\n",
    "    Vin = torch.exp(Vin)*10  # Vin is in V\n",
    "    Vf = torch.exp(Vf)  # Vf is in V\n",
    "    return L, RL, C, RC, Rdson, Rload, Vin, Vf\n",
    "\n",
    "\n",
    "# --- Physics Forward RK4 ---\n",
    "def physics_forward(\n",
    "    x_n: torch.Tensor, params: torch.Tensor, normalizer: Normalizer\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given x_n = [i_n, v_n, i_np1, v_np1, D, dt] and predicted params,\n",
    "    reconstruct x_np1_pred = [i_np1, v_np1].\n",
    "    \"\"\"\n",
    "    # unnormalize the input data\n",
    "    x_n = normalizer.denormalize(x_n)\n",
    "    \n",
    "    # unpack inputs\n",
    "    i_n = x_n[:, 0:1]\n",
    "    v_n = x_n[:, 1:2]\n",
    "    D = x_n[:, 4:5]\n",
    "    dt = x_n[:, 5:6]\n",
    "    \n",
    "    # unpack params\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = torch.split(params, 1, dim=1)\n",
    "\n",
    "    # the model actually predicts the logarithm of the parameters:denormalize parameters\n",
    "\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = denorm_physical_params(\n",
    "        L, RL, C, RC, Rdson, Rload, Vin, Vf\n",
    "    )\n",
    "\n",
    "    i_np1_pred, v_np1_pred = predict_next_state(\n",
    "        i_n, v_n, D, dt, L, RL, C, RC, Rdson, Rload, Vin, Vf\n",
    "    )\n",
    "\n",
    "    return torch.cat([i_np1_pred, v_np1_pred], dim=1)\n",
    "\n",
    "\n",
    "def predict_next_state(\n",
    "    i_n: torch.Tensor,\n",
    "    v_n: torch.Tensor,\n",
    "    D: torch.Tensor,\n",
    "    dt: torch.Tensor,\n",
    "    L: torch.Tensor,\n",
    "    RL: torch.Tensor,\n",
    "    C: torch.Tensor,\n",
    "    RC: torch.Tensor,\n",
    "    Rdson: torch.Tensor,\n",
    "    Rload: torch.Tensor,\n",
    "    Vin: torch.Tensor,\n",
    "    Vf: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Predict the next state [i_np1, v_np1] using the RK4 method.\"\"\"\n",
    "\n",
    "    def f(i: torch.Tensor, v: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        di = -((D * Rdson + RL) * i + v - D * Vin + (1 - D) * Vf) / L\n",
    "        dv = (C * RC * Rload * di + Rload * i - v) / (C * (RC + Rload))\n",
    "        return di, dv\n",
    "\n",
    "    # RK4 steps\n",
    "    k1_i, k1_v = f(i_n, v_n)\n",
    "    k2_i, k2_v = f(i_n + 0.5 * dt * k1_i, v_n + 0.5 * dt * k1_v)\n",
    "    k3_i, k3_v = f(i_n + 0.5 * dt * k2_i, v_n + 0.5 * dt * k2_v)\n",
    "    k4_i, k4_v = f(i_n + dt * k3_i, v_n + dt * k3_v)\n",
    "\n",
    "    i_np1_pred = i_n + (dt / 6) * (k1_i + 2 * k2_i + 2 * k3_i + k4_i)\n",
    "    v_np1_pred = v_n + (dt / 6) * (k1_v + 2 * k2_v + 2 * k3_v + k4_v)\n",
    "    return i_np1_pred, v_np1_pred\n",
    "\n",
    "\n",
    "# --- Loss ---\n",
    "def compute_loss(x_np1_pred: torch.Tensor, x_np1_true: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sum((x_np1_pred - x_np1_true) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aaa6a0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JC28LS\\AppData\\Local\\Temp\\ipykernel_2712\\3022096116.py:55: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  X_denorm = X_norm * self.std + self.mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "loss: 2.493e+15, L: 0.000001 H, RL: 0.839566 Ohm, C: 0.000001 F\n",
      "RC: 1.084265 Ohm, Rdson: 0.001093 Ohm, Rload: 0.922742 Ohm, Vin: 0.897291 V, Vf: 1.017835 V\n",
      "Epoch 1001:\n",
      "loss: 2.419e+11, L: 0.000002 H, RL: 0.561840 Ohm, C: 0.000002 F\n",
      "RC: 0.873726 Ohm, Rdson: 0.000925 Ohm, Rload: 1.038574 Ohm, Vin: 0.958946 V, Vf: 0.675467 V\n",
      "Epoch 2001:\n",
      "loss: 5.547e+10, L: 0.000002 H, RL: 0.523290 Ohm, C: 0.000002 F\n",
      "RC: 0.820186 Ohm, Rdson: 0.000882 Ohm, Rload: 1.094938 Ohm, Vin: 0.971882 V, Vf: 0.627829 V\n",
      "Epoch 3001:\n",
      "loss: 2.097e+10, L: 0.000002 H, RL: 0.499905 Ohm, C: 0.000003 F\n",
      "RC: 0.784087 Ohm, Rdson: 0.000855 Ohm, Rload: 1.135669 Ohm, Vin: 0.982134 V, Vf: 0.598641 V\n",
      "Epoch 4001:\n",
      "loss: 9.577e+09, L: 0.000002 H, RL: 0.482155 Ohm, C: 0.000003 F\n",
      "RC: 0.754917 Ohm, Rdson: 0.000833 Ohm, Rload: 1.169956 Ohm, Vin: 0.991397 V, Vf: 0.576304 V\n",
      "Epoch 5001:\n",
      "loss: 4.801e+09, L: 0.000002 H, RL: 0.467246 Ohm, C: 0.000003 F\n",
      "RC: 0.729265 Ohm, Rdson: 0.000815 Ohm, Rload: 1.200933 Ohm, Vin: 1.000329 V, Vf: 0.557416 V\n",
      "Epoch 6001:\n",
      "loss: 2.533e+09, L: 0.000002 H, RL: 0.454018 Ohm, C: 0.000004 F\n",
      "RC: 0.705649 Ohm, Rdson: 0.000798 Ohm, Rload: 1.229983 Ohm, Vin: 1.009259 V, Vf: 0.540565 V\n",
      "Epoch 7001:\n",
      "loss: 1.378e+09, L: 0.000003 H, RL: 0.441901 Ohm, C: 0.000004 F\n",
      "RC: 0.683327 Ohm, Rdson: 0.000783 Ohm, Rload: 1.257781 Ohm, Vin: 1.018371 V, Vf: 0.525063 V\n",
      "Epoch 8001:\n",
      "loss: 7.641e+08, L: 0.000003 H, RL: 0.430587 Ohm, C: 0.000005 F\n",
      "RC: 0.661905 Ohm, Rdson: 0.000768 Ohm, Rload: 1.284672 Ohm, Vin: 1.027777 V, Vf: 0.510537 V\n",
      "Epoch 9001:\n",
      "loss: 4.291e+08, L: 0.000003 H, RL: 0.419896 Ohm, C: 0.000005 F\n",
      "RC: 0.641166 Ohm, Rdson: 0.000754 Ohm, Rload: 1.310833 Ohm, Vin: 1.037555 V, Vf: 0.496776 V\n",
      "Epoch 10001:\n",
      "loss: 2.430e+08, L: 0.000003 H, RL: 0.409719 Ohm, C: 0.000006 F\n",
      "RC: 0.620999 Ohm, Rdson: 0.000740 Ohm, Rload: 1.336348 Ohm, Vin: 1.047750 V, Vf: 0.483648 V\n",
      "Epoch 11001:\n",
      "loss: 1.385e+08, L: 0.000003 H, RL: 0.399983 Ohm, C: 0.000006 F\n",
      "RC: 0.601336 Ohm, Rdson: 0.000727 Ohm, Rload: 1.361266 Ohm, Vin: 1.058397 V, Vf: 0.471072 V\n",
      "Epoch 12001:\n",
      "loss: 7.930e+07, L: 0.000003 H, RL: 0.390640 Ohm, C: 0.000007 F\n",
      "RC: 0.582153 Ohm, Rdson: 0.000715 Ohm, Rload: 1.385609 Ohm, Vin: 1.069516 V, Vf: 0.458984 V\n",
      "Epoch 13001:\n",
      "loss: 4.558e+07, L: 0.000003 H, RL: 0.381656 Ohm, C: 0.000008 F\n",
      "RC: 0.563440 Ohm, Rdson: 0.000702 Ohm, Rload: 1.409385 Ohm, Vin: 1.081134 V, Vf: 0.447340 V\n",
      "Epoch 14001:\n",
      "loss: 2.627e+07, L: 0.000003 H, RL: 0.373005 Ohm, C: 0.000009 F\n",
      "RC: 0.545196 Ohm, Rdson: 0.000690 Ohm, Rload: 1.432601 Ohm, Vin: 1.093276 V, Vf: 0.436099 V\n",
      "Epoch 15001:\n",
      "loss: 1.518e+07, L: 0.000003 H, RL: 0.364662 Ohm, C: 0.000009 F\n",
      "RC: 0.527424 Ohm, Rdson: 0.000679 Ohm, Rload: 1.455257 Ohm, Vin: 1.105978 V, Vf: 0.425223 V\n",
      "Epoch 16001:\n",
      "loss: 8.788e+06, L: 0.000003 H, RL: 0.356612 Ohm, C: 0.000010 F\n",
      "RC: 0.510137 Ohm, Rdson: 0.000667 Ohm, Rload: 1.477348 Ohm, Vin: 1.119285 V, Vf: 0.414673 V\n",
      "Epoch 17001:\n",
      "loss: 5.094e+06, L: 0.000004 H, RL: 0.348839 Ohm, C: 0.000011 F\n",
      "RC: 0.493342 Ohm, Rdson: 0.000656 Ohm, Rload: 1.498880 Ohm, Vin: 1.133247 V, Vf: 0.404416 V\n",
      "Epoch 18001:\n",
      "loss: 2.955e+06, L: 0.000004 H, RL: 0.341331 Ohm, C: 0.000013 F\n",
      "RC: 0.477054 Ohm, Rdson: 0.000646 Ohm, Rload: 1.519837 Ohm, Vin: 1.147951 V, Vf: 0.394405 V\n",
      "Epoch 19001:\n",
      "loss: 1.714e+06, L: 0.000004 H, RL: 0.334081 Ohm, C: 0.000014 F\n",
      "RC: 0.461289 Ohm, Rdson: 0.000635 Ohm, Rload: 1.540201 Ohm, Vin: 1.163494 V, Vf: 0.384602 V\n",
      "Epoch 20001:\n",
      "loss: 9.934e+05, L: 0.000004 H, RL: 0.327084 Ohm, C: 0.000015 F\n",
      "RC: 0.446074 Ohm, Rdson: 0.000625 Ohm, Rload: 1.559939 Ohm, Vin: 1.180024 V, Vf: 0.374957 V\n",
      "Epoch 21001:\n",
      "loss: 5.753e+05, L: 0.000004 H, RL: 0.320346 Ohm, C: 0.000017 F\n",
      "RC: 0.431452 Ohm, Rdson: 0.000615 Ohm, Rload: 1.579003 Ohm, Vin: 1.197758 V, Vf: 0.365425 V\n",
      "Epoch 22001:\n",
      "loss: 3.333e+05, L: 0.000004 H, RL: 0.313880 Ohm, C: 0.000019 F\n",
      "RC: 0.417492 Ohm, Rdson: 0.000606 Ohm, Rload: 1.597324 Ohm, Vin: 1.217017 V, Vf: 0.355956 V\n",
      "Epoch 23001:\n",
      "loss: 1.943e+05, L: 0.000004 H, RL: 0.307722 Ohm, C: 0.000021 F\n",
      "RC: 0.404316 Ohm, Rdson: 0.000597 Ohm, Rload: 1.614781 Ohm, Vin: 1.238323 V, Vf: 0.346496 V\n",
      "Epoch 24001:\n",
      "loss: 1.156e+05, L: 0.000004 H, RL: 0.301938 Ohm, C: 0.000023 F\n",
      "RC: 0.392130 Ohm, Rdson: 0.000588 Ohm, Rload: 1.631224 Ohm, Vin: 1.262578 V, Vf: 0.336981 V\n",
      "Epoch 25001:\n",
      "loss: 7.228e+04, L: 0.000004 H, RL: 0.296648 Ohm, C: 0.000025 F\n",
      "RC: 0.381291 Ohm, Rdson: 0.000581 Ohm, Rload: 1.646453 Ohm, Vin: 1.291425 V, Vf: 0.327327 V\n",
      "Epoch 26001:\n",
      "loss: 4.957e+04, L: 0.000005 H, RL: 0.292050 Ohm, C: 0.000028 F\n",
      "RC: 0.372378 Ohm, Rdson: 0.000574 Ohm, Rload: 1.660273 Ohm, Vin: 1.327908 V, Vf: 0.317396 V\n",
      "Epoch 27001:\n",
      "loss: 3.832e+04, L: 0.000005 H, RL: 0.288430 Ohm, C: 0.000030 F\n",
      "RC: 0.366269 Ohm, Rdson: 0.000569 Ohm, Rload: 1.672656 Ohm, Vin: 1.377729 V, Vf: 0.306937 V\n",
      "Epoch 28001:\n",
      "loss: 3.260e+04, L: 0.000005 H, RL: 0.286115 Ohm, C: 0.000032 F\n",
      "RC: 0.364084 Ohm, Rdson: 0.000566 Ohm, Rload: 1.684074 Ohm, Vin: 1.451419 V, Vf: 0.295486 V\n",
      "Epoch 29001:\n",
      "loss: 2.853e+04, L: 0.000005 H, RL: 0.285284 Ohm, C: 0.000033 F\n",
      "RC: 0.366830 Ohm, Rdson: 0.000566 Ohm, Rload: 1.696045 Ohm, Vin: 1.568456 V, Vf: 0.282299 V\n",
      "Epoch 30001:\n",
      "loss: 2.417e+04, L: 0.000005 H, RL: 0.285713 Ohm, C: 0.000033 F\n",
      "RC: 0.374777 Ohm, Rdson: 0.000568 Ohm, Rload: 1.711759 Ohm, Vin: 1.767122 V, Vf: 0.266539 V\n",
      "Epoch 31001:\n",
      "loss: 1.917e+04, L: 0.000005 H, RL: 0.286765 Ohm, C: 0.000032 F\n",
      "RC: 0.387318 Ohm, Rdson: 0.000571 Ohm, Rload: 1.735939 Ohm, Vin: 2.131688 V, Vf: 0.248011 V\n",
      "Epoch 32001:\n",
      "loss: 1.398e+04, L: 0.000005 H, RL: 0.287825 Ohm, C: 0.000031 F\n",
      "RC: 0.403601 Ohm, Rdson: 0.000575 Ohm, Rload: 1.772133 Ohm, Vin: 2.862104 V, Vf: 0.227699 V\n",
      "Epoch 33001:\n",
      "loss: 9.495e+03, L: 0.000005 H, RL: 0.288618 Ohm, C: 0.000029 F\n",
      "RC: 0.422477 Ohm, Rdson: 0.000578 Ohm, Rload: 1.814997 Ohm, Vin: 4.296697 V, Vf: 0.206954 V\n",
      "Epoch 34001:\n",
      "loss: 6.720e+03, L: 0.000005 H, RL: 0.289138 Ohm, C: 0.000028 F\n",
      "RC: 0.442837 Ohm, Rdson: 0.000582 Ohm, Rload: 1.845499 Ohm, Vin: 5.782014 V, Vf: 0.186859 V\n",
      "Epoch 35001:\n",
      "loss: 4.885e+03, L: 0.000005 H, RL: 0.289232 Ohm, C: 0.000026 F\n",
      "RC: 0.465890 Ohm, Rdson: 0.000587 Ohm, Rload: 1.863047 Ohm, Vin: 6.338797 V, Vf: 0.168479 V\n",
      "Epoch 36001:\n",
      "loss: 3.414e+03, L: 0.000005 H, RL: 0.288838 Ohm, C: 0.000025 F\n",
      "RC: 0.493461 Ohm, Rdson: 0.000592 Ohm, Rload: 1.880039 Ohm, Vin: 6.676733 V, Vf: 0.151633 V\n",
      "Epoch 37001:\n",
      "loss: 2.247e+03, L: 0.000006 H, RL: 0.287944 Ohm, C: 0.000023 F\n",
      "RC: 0.526200 Ohm, Rdson: 0.000595 Ohm, Rload: 1.897597 Ohm, Vin: 7.246856 V, Vf: 0.136293 V\n",
      "Epoch 38001:\n",
      "loss: 1.360e+03, L: 0.000006 H, RL: 0.286600 Ohm, C: 0.000022 F\n",
      "RC: 0.563412 Ohm, Rdson: 0.000596 Ohm, Rload: 1.909930 Ohm, Vin: 8.309683 V, Vf: 0.122486 V\n",
      "Epoch 39001:\n",
      "loss: 7.521e+02, L: 0.000006 H, RL: 0.284675 Ohm, C: 0.000020 F\n",
      "RC: 0.602908 Ohm, Rdson: 0.000593 Ohm, Rload: 1.907631 Ohm, Vin: 9.730634 V, Vf: 0.110293 V\n",
      "Epoch 40001:\n",
      "loss: 4.046e+02, L: 0.000006 H, RL: 0.281856 Ohm, C: 0.000019 F\n",
      "RC: 0.642887 Ohm, Rdson: 0.000588 Ohm, Rload: 1.892589 Ohm, Vin: 10.855673 V, Vf: 0.100234 V\n",
      "Epoch 41001:\n",
      "loss: 2.237e+02, L: 0.000006 H, RL: 0.278325 Ohm, C: 0.000018 F\n",
      "RC: 0.683039 Ohm, Rdson: 0.000584 Ohm, Rload: 1.892489 Ohm, Vin: 11.578944 V, Vf: 0.092733 V\n",
      "Epoch 42001:\n",
      "loss: 1.266e+02, L: 0.000006 H, RL: 0.274698 Ohm, C: 0.000018 F\n",
      "RC: 0.721858 Ohm, Rdson: 0.000582 Ohm, Rload: 1.917960 Ohm, Vin: 11.877898 V, Vf: 0.087020 V\n",
      "Epoch 43001:\n",
      "loss: 7.335e+01, L: 0.000007 H, RL: 0.271287 Ohm, C: 0.000017 F\n",
      "RC: 0.758529 Ohm, Rdson: 0.000581 Ohm, Rload: 1.964142 Ohm, Vin: 11.696080 V, Vf: 0.082047 V\n",
      "Epoch 44001:\n",
      "loss: 4.425e+01, L: 0.000007 H, RL: 0.268030 Ohm, C: 0.000017 F\n",
      "RC: 0.794509 Ohm, Rdson: 0.000578 Ohm, Rload: 2.027572 Ohm, Vin: 11.173906 V, Vf: 0.077154 V\n",
      "Epoch 45001:\n",
      "loss: 2.813e+01, L: 0.000007 H, RL: 0.264699 Ohm, C: 0.000016 F\n",
      "RC: 0.833472 Ohm, Rdson: 0.000575 Ohm, Rload: 2.105707 Ohm, Vin: 10.438190 V, Vf: 0.071981 V\n",
      "Epoch 46001:\n",
      "loss: 1.867e+01, L: 0.000007 H, RL: 0.261216 Ohm, C: 0.000016 F\n",
      "RC: 0.878722 Ohm, Rdson: 0.000571 Ohm, Rload: 2.197852 Ohm, Vin: 9.543840 V, Vf: 0.066519 V\n",
      "Epoch 47001:\n",
      "loss: 1.260e+01, L: 0.000007 H, RL: 0.257786 Ohm, C: 0.000015 F\n",
      "RC: 0.929411 Ohm, Rdson: 0.000569 Ohm, Rload: 2.299025 Ohm, Vin: 8.551363 V, Vf: 0.061070 V\n",
      "Epoch 48001:\n",
      "loss: 8.519e+00, L: 0.000008 H, RL: 0.254838 Ohm, C: 0.000015 F\n",
      "RC: 0.981659 Ohm, Rdson: 0.000569 Ohm, Rload: 2.399632 Ohm, Vin: 7.542184 V, Vf: 0.056036 V\n",
      "Epoch 49001:\n",
      "loss: 5.686e+00, L: 0.000008 H, RL: 0.253478 Ohm, C: 0.000015 F\n",
      "RC: 1.035128 Ohm, Rdson: 0.000574 Ohm, Rload: 2.446541 Ohm, Vin: 6.605592 V, Vf: 0.051734 V\n",
      "Epoch 50001:\n",
      "loss: 3.808e+00, L: 0.000008 H, RL: 0.253920 Ohm, C: 0.000014 F\n",
      "RC: 1.088335 Ohm, Rdson: 0.000582 Ohm, Rload: 2.419159 Ohm, Vin: 5.791422 V, Vf: 0.048214 V\n",
      "Epoch 51001:\n",
      "loss: 2.528e+00, L: 0.000009 H, RL: 0.256182 Ohm, C: 0.000013 F\n",
      "RC: 1.141913 Ohm, Rdson: 0.000593 Ohm, Rload: 2.320380 Ohm, Vin: 5.124193 V, Vf: 0.045243 V\n",
      "Epoch 52001:\n",
      "loss: 4.559e+01, L: 0.000009 H, RL: 0.260390 Ohm, C: 0.000013 F\n",
      "RC: 1.197655 Ohm, Rdson: 0.000604 Ohm, Rload: 2.178103 Ohm, Vin: 4.572850 V, Vf: 0.042532 V\n",
      "Epoch 53001:\n",
      "loss: 9.882e-01, L: 0.000009 H, RL: 0.265174 Ohm, C: 0.000012 F\n",
      "RC: 1.248559 Ohm, Rdson: 0.000614 Ohm, Rload: 1.998016 Ohm, Vin: 4.108340 V, Vf: 0.039867 V\n",
      "Epoch 54001:\n",
      "loss: 1.360e+00, L: 0.000009 H, RL: 0.273612 Ohm, C: 0.000011 F\n",
      "RC: 1.310191 Ohm, Rdson: 0.000629 Ohm, Rload: 1.760967 Ohm, Vin: 3.678834 V, Vf: 0.036846 V\n",
      "Epoch 55001:\n",
      "loss: 3.281e-01, L: 0.000009 H, RL: 0.280708 Ohm, C: 0.000011 F\n",
      "RC: 1.361940 Ohm, Rdson: 0.000641 Ohm, Rload: 1.605659 Ohm, Vin: 3.343170 V, Vf: 0.034363 V\n",
      "Epoch 56001:\n",
      "loss: 4.529e-01, L: 0.000010 H, RL: 0.292322 Ohm, C: 0.000010 F\n",
      "RC: 1.430100 Ohm, Rdson: 0.000660 Ohm, Rload: 1.406164 Ohm, Vin: 3.039126 V, Vf: 0.031210 V\n",
      "Epoch 57001:\n",
      "loss: 1.066e-01, L: 0.000010 H, RL: 0.301469 Ohm, C: 0.000009 F\n",
      "RC: 1.483870 Ohm, Rdson: 0.000674 Ohm, Rload: 1.293766 Ohm, Vin: 2.848671 V, Vf: 0.028861 V\n",
      "Epoch 58001:\n",
      "loss: 6.041e-02, L: 0.000010 H, RL: 0.312401 Ohm, C: 0.000009 F\n",
      "RC: 1.548271 Ohm, Rdson: 0.000693 Ohm, Rload: 1.162567 Ohm, Vin: 2.717499 V, Vf: 0.025790 V\n",
      "Epoch 59001:\n",
      "loss: 3.589e-02, L: 0.000010 H, RL: 0.321801 Ohm, C: 0.000008 F\n",
      "RC: 1.610228 Ohm, Rdson: 0.000710 Ohm, Rload: 1.065744 Ohm, Vin: 2.660693 V, Vf: 0.022796 V\n",
      "Epoch 60001:\n",
      "loss: 2.690e-02, L: 0.000011 H, RL: 0.331042 Ohm, C: 0.000008 F\n",
      "RC: 1.679333 Ohm, Rdson: 0.000729 Ohm, Rload: 1.005433 Ohm, Vin: 2.667340 V, Vf: 0.019710 V\n",
      "Epoch 61001:\n",
      "loss: 1.137e+00, L: 0.000011 H, RL: 0.337578 Ohm, C: 0.000007 F\n",
      "RC: 1.740998 Ohm, Rdson: 0.000744 Ohm, Rload: 0.976956 Ohm, Vin: 2.669663 V, Vf: 0.017501 V\n",
      "Epoch 62001:\n",
      "loss: 1.176e-02, L: 0.000012 H, RL: 0.344380 Ohm, C: 0.000007 F\n",
      "RC: 1.803746 Ohm, Rdson: 0.000757 Ohm, Rload: 0.965645 Ohm, Vin: 2.679688 V, Vf: 0.015675 V\n",
      "Epoch 63001:\n",
      "loss: 9.904e-03, L: 0.000012 H, RL: 0.352371 Ohm, C: 0.000006 F\n",
      "RC: 1.878354 Ohm, Rdson: 0.000772 Ohm, Rload: 0.958716 Ohm, Vin: 2.717163 V, Vf: 0.013699 V\n",
      "Epoch 64001:\n",
      "loss: 7.100e-01, L: 0.000012 H, RL: 0.358461 Ohm, C: 0.000006 F\n",
      "RC: 1.932147 Ohm, Rdson: 0.000782 Ohm, Rload: 0.957408 Ohm, Vin: 2.736180 V, Vf: 0.012434 V\n",
      "Epoch 65001:\n",
      "loss: 7.315e-03, L: 0.000013 H, RL: 0.366428 Ohm, C: 0.000006 F\n",
      "RC: 1.992922 Ohm, Rdson: 0.000792 Ohm, Rload: 0.961852 Ohm, Vin: 2.751345 V, Vf: 0.011224 V\n",
      "Epoch 66001:\n",
      "loss: 8.115e-03, L: 0.000014 H, RL: 0.374294 Ohm, C: 0.000005 F\n",
      "RC: 2.049540 Ohm, Rdson: 0.000799 Ohm, Rload: 0.970219 Ohm, Vin: 2.764339 V, Vf: 0.010108 V\n",
      "Epoch 67001:\n",
      "loss: 6.540e-03, L: 0.000014 H, RL: 0.381247 Ohm, C: 0.000005 F\n",
      "RC: 2.097307 Ohm, Rdson: 0.000805 Ohm, Rload: 0.980793 Ohm, Vin: 2.766563 V, Vf: 0.009234 V\n",
      "Epoch 68001:\n",
      "loss: 6.094e-03, L: 0.000015 H, RL: 0.387885 Ohm, C: 0.000005 F\n",
      "RC: 2.141528 Ohm, Rdson: 0.000811 Ohm, Rload: 0.990136 Ohm, Vin: 2.733279 V, Vf: 0.008510 V\n",
      "Epoch 69001:\n",
      "loss: 5.839e-03, L: 0.000015 H, RL: 0.396572 Ohm, C: 0.000005 F\n",
      "RC: 2.193374 Ohm, Rdson: 0.000816 Ohm, Rload: 1.008928 Ohm, Vin: 2.715566 V, Vf: 0.007727 V\n",
      "Epoch 70001:\n",
      "loss: 7.063e-03, L: 0.000016 H, RL: 0.403847 Ohm, C: 0.000005 F\n",
      "RC: 2.238093 Ohm, Rdson: 0.000820 Ohm, Rload: 1.023512 Ohm, Vin: 2.660832 V, Vf: 0.007195 V\n",
      "Epoch 71001:\n",
      "loss: 7.969e-03, L: 0.000016 H, RL: 0.411119 Ohm, C: 0.000005 F\n",
      "RC: 2.283408 Ohm, Rdson: 0.000824 Ohm, Rload: 1.039825 Ohm, Vin: 2.592663 V, Vf: 0.006764 V\n",
      "Epoch 72001:\n",
      "loss: 5.316e-03, L: 0.000016 H, RL: 0.417520 Ohm, C: 0.000004 F\n",
      "RC: 2.325783 Ohm, Rdson: 0.000827 Ohm, Rload: 1.054798 Ohm, Vin: 2.524653 V, Vf: 0.006399 V\n",
      "Epoch 73001:\n",
      "loss: 5.746e-03, L: 0.000017 H, RL: 0.421978 Ohm, C: 0.000004 F\n",
      "RC: 2.362266 Ohm, Rdson: 0.000829 Ohm, Rload: 1.067644 Ohm, Vin: 2.460552 V, Vf: 0.006087 V\n",
      "Epoch 74001:\n",
      "loss: 5.049e-02, L: 0.000017 H, RL: 0.428679 Ohm, C: 0.000004 F\n",
      "RC: 2.409362 Ohm, Rdson: 0.000836 Ohm, Rload: 1.083105 Ohm, Vin: 2.375117 V, Vf: 0.005801 V\n",
      "Epoch 75001:\n",
      "loss: 1.120e-02, L: 0.000017 H, RL: 0.430057 Ohm, C: 0.000004 F\n",
      "RC: 2.437717 Ohm, Rdson: 0.000835 Ohm, Rload: 1.092415 Ohm, Vin: 2.324583 V, Vf: 0.005598 V\n",
      "Epoch 76001:\n",
      "loss: 1.616e-01, L: 0.000018 H, RL: 0.433561 Ohm, C: 0.000004 F\n",
      "RC: 2.478015 Ohm, Rdson: 0.000839 Ohm, Rload: 1.104601 Ohm, Vin: 2.263593 V, Vf: 0.005391 V\n",
      "Epoch 77001:\n",
      "loss: 4.454e-03, L: 0.000018 H, RL: 0.434074 Ohm, C: 0.000004 F\n",
      "RC: 2.507667 Ohm, Rdson: 0.000839 Ohm, Rload: 1.114159 Ohm, Vin: 2.206170 V, Vf: 0.005262 V\n",
      "Epoch 78001:\n",
      "loss: 7.797e-01, L: 0.000018 H, RL: 0.435508 Ohm, C: 0.000004 F\n",
      "RC: 2.540116 Ohm, Rdson: 0.000842 Ohm, Rload: 1.126610 Ohm, Vin: 2.148906 V, Vf: 0.005155 V\n",
      "Epoch 79001:\n",
      "loss: 5.327e-03, L: 0.000018 H, RL: 0.438079 Ohm, C: 0.000004 F\n",
      "RC: 2.581841 Ohm, Rdson: 0.000847 Ohm, Rload: 1.135554 Ohm, Vin: 2.106041 V, Vf: 0.004996 V\n",
      "Epoch 80001:\n",
      "loss: 3.900e-03, L: 0.000018 H, RL: 0.435962 Ohm, C: 0.000004 F\n",
      "RC: 2.606890 Ohm, Rdson: 0.000847 Ohm, Rload: 1.141295 Ohm, Vin: 2.066624 V, Vf: 0.004926 V\n",
      "Epoch 81001:\n",
      "loss: 2.603e-02, L: 0.000019 H, RL: 0.437981 Ohm, C: 0.000004 F\n",
      "RC: 2.649513 Ohm, Rdson: 0.000851 Ohm, Rload: 1.153462 Ohm, Vin: 2.019447 V, Vf: 0.004803 V\n",
      "Epoch 82001:\n",
      "loss: 1.832e-01, L: 0.000019 H, RL: 0.435922 Ohm, C: 0.000004 F\n",
      "RC: 2.671877 Ohm, Rdson: 0.000852 Ohm, Rload: 1.159645 Ohm, Vin: 1.988652 V, Vf: 0.004752 V\n",
      "Epoch 83001:\n",
      "loss: 3.117e-03, L: 0.000019 H, RL: 0.435391 Ohm, C: 0.000004 F\n",
      "RC: 2.709078 Ohm, Rdson: 0.000855 Ohm, Rload: 1.166523 Ohm, Vin: 1.956307 V, Vf: 0.004681 V\n",
      "Epoch 84001:\n",
      "loss: 2.968e-03, L: 0.000019 H, RL: 0.434145 Ohm, C: 0.000004 F\n",
      "RC: 2.739238 Ohm, Rdson: 0.000857 Ohm, Rload: 1.173465 Ohm, Vin: 1.927990 V, Vf: 0.004630 V\n",
      "Epoch 85001:\n",
      "loss: 2.847e-03, L: 0.000019 H, RL: 0.433964 Ohm, C: 0.000004 F\n",
      "RC: 2.775591 Ohm, Rdson: 0.000860 Ohm, Rload: 1.182309 Ohm, Vin: 1.897843 V, Vf: 0.004570 V\n",
      "Epoch 86001:\n",
      "loss: 5.245e-03, L: 0.000019 H, RL: 0.432322 Ohm, C: 0.000004 F\n",
      "RC: 2.812525 Ohm, Rdson: 0.000861 Ohm, Rload: 1.189846 Ohm, Vin: 1.866789 V, Vf: 0.004543 V\n",
      "Epoch 87001:\n",
      "loss: 5.690e-02, L: 0.000019 H, RL: 0.431636 Ohm, C: 0.000004 F\n",
      "RC: 2.849676 Ohm, Rdson: 0.000859 Ohm, Rload: 1.200179 Ohm, Vin: 1.837231 V, Vf: 0.004490 V\n",
      "Epoch 88001:\n",
      "loss: 2.905e-02, L: 0.000019 H, RL: 0.428268 Ohm, C: 0.000004 F\n",
      "RC: 2.874210 Ohm, Rdson: 0.000859 Ohm, Rload: 1.202274 Ohm, Vin: 1.820515 V, Vf: 0.004492 V\n",
      "Epoch 89001:\n",
      "loss: 1.862e-01, L: 0.000019 H, RL: 0.423423 Ohm, C: 0.000003 F\n",
      "RC: 2.895334 Ohm, Rdson: 0.000855 Ohm, Rload: 1.206615 Ohm, Vin: 1.799603 V, Vf: 0.004490 V\n",
      "Epoch 90001:\n",
      "loss: 2.208e-03, L: 0.000019 H, RL: 0.422142 Ohm, C: 0.000003 F\n",
      "RC: 2.933167 Ohm, Rdson: 0.000852 Ohm, Rload: 1.212641 Ohm, Vin: 1.776068 V, Vf: 0.004462 V\n",
      "Epoch 91001:\n",
      "loss: 2.097e-03, L: 0.000019 H, RL: 0.419627 Ohm, C: 0.000003 F\n",
      "RC: 2.965441 Ohm, Rdson: 0.000847 Ohm, Rload: 1.218945 Ohm, Vin: 1.750622 V, Vf: 0.004436 V\n",
      "Epoch 92001:\n",
      "loss: 5.260e-02, L: 0.000019 H, RL: 0.420155 Ohm, C: 0.000003 F\n",
      "RC: 3.015882 Ohm, Rdson: 0.000845 Ohm, Rload: 1.230893 Ohm, Vin: 1.722514 V, Vf: 0.004406 V\n",
      "Epoch 93001:\n",
      "loss: 7.273e-03, L: 0.000019 H, RL: 0.414662 Ohm, C: 0.000003 F\n",
      "RC: 3.043495 Ohm, Rdson: 0.000831 Ohm, Rload: 1.235021 Ohm, Vin: 1.697903 V, Vf: 0.004386 V\n",
      "Epoch 94001:\n",
      "loss: 2.417e-03, L: 0.000019 H, RL: 0.411169 Ohm, C: 0.000003 F\n",
      "RC: 3.067421 Ohm, Rdson: 0.000828 Ohm, Rload: 1.237283 Ohm, Vin: 1.686003 V, Vf: 0.004396 V\n",
      "Epoch 95001:\n",
      "loss: 1.473e-02, L: 0.000019 H, RL: 0.408550 Ohm, C: 0.000003 F\n",
      "RC: 3.103721 Ohm, Rdson: 0.000820 Ohm, Rload: 1.244730 Ohm, Vin: 1.661868 V, Vf: 0.004378 V\n",
      "Epoch 96001:\n",
      "loss: 1.929e-02, L: 0.000019 H, RL: 0.407181 Ohm, C: 0.000003 F\n",
      "RC: 3.156230 Ohm, Rdson: 0.000812 Ohm, Rload: 1.255320 Ohm, Vin: 1.628035 V, Vf: 0.004339 V\n",
      "Epoch 97001:\n",
      "loss: 8.412e-01, L: 0.000019 H, RL: 0.403732 Ohm, C: 0.000003 F\n",
      "RC: 3.170156 Ohm, Rdson: 0.000807 Ohm, Rload: 1.258688 Ohm, Vin: 1.617667 V, Vf: 0.004362 V\n",
      "Epoch 98001:\n",
      "loss: 2.196e-03, L: 0.000019 H, RL: 0.398480 Ohm, C: 0.000003 F\n",
      "RC: 3.206870 Ohm, Rdson: 0.000795 Ohm, Rload: 1.262368 Ohm, Vin: 1.595779 V, Vf: 0.004345 V\n",
      "Epoch 99001:\n",
      "loss: 1.641e-03, L: 0.000019 H, RL: 0.395688 Ohm, C: 0.000003 F\n",
      "RC: 3.246732 Ohm, Rdson: 0.000789 Ohm, Rload: 1.269876 Ohm, Vin: 1.568936 V, Vf: 0.004339 V\n"
     ]
    }
   ],
   "source": [
    "Rload = Rload1 * np.ones_like(i_n)\n",
    "\n",
    "# train the model for 10 epochs\n",
    "\n",
    "X_t = torch.tensor(X_norm, dtype=torch.float32)\n",
    "Rload_t = torch.tensor(Rload, dtype=torch.float32).view(-1, 1)\n",
    "model = ParamEstimator(input_dim=6, hidden_layers=[32, 32])\n",
    "device = \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "X_t = X_t.to(device)\n",
    "Rload_t = Rload_t.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=adam_lr)\n",
    "\n",
    "for epoch in range(int(10e4)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    params_pred = model(X_t)\n",
    "    x_n1_pred = physics_forward(X_t, params_pred, normalizer)\n",
    "    loss = compute_loss(X_t[:, :2], x_n1_pred)\n",
    "    \n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get explicit predictions\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = torch.split(params_pred, 1, dim=1)\n",
    "    \n",
    "    # denormalize parameters and print the predicted values\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = denorm_physical_params(\n",
    "        L, RL, C, RC, Rdson, Rload, Vin, Vf\n",
    "    )\n",
    "    \n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(f\"loss: {loss.item():.3e}, L: {L.mean().item():.6f} H, RL: {RL.mean().item():.6f} Ohm, C: {C.mean().item():.6f} F\")\n",
    "        print(f\"RC: {RC.mean().item():.6f} Ohm, Rdson: {Rdson.mean().item():.6f} Ohm, Rload: {Rload.mean().item():.6f} Ohm, Vin: {Vin.mean().item():.6f} V, Vf: {Vf.mean().item():.6f} V\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235459ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pysical_param_bounds = (1e-5, 1e-2)\n",
    "\n",
    "def denorm_physical_params(\n",
    "    L: torch.Tensor,\n",
    "    RL: torch.Tensor,\n",
    "    C: torch.Tensor,\n",
    "    RC: torch.Tensor,\n",
    "    Rdson: torch.Tensor,\n",
    "    Rload: torch.Tensor,\n",
    "    Vin: torch.Tensor,\n",
    "    Vf: torch.Tensor,\n",
    ") -> Tuple[\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "    torch.Tensor,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Denormalize the physical parameters from their logarithmic form.\n",
    "    The parameters are expected to be in the logarithmic scale.\n",
    "    \"\"\"\n",
    "    L = torch.clamp(L, *pysical_param_bounds)*1e-6\n",
    "    RL = torch.clamp(RL, *pysical_param_bounds)\n",
    "    C = torch.clamp(C, *pysical_param_bounds) * 1e-6  # assume the network gets the uF value\n",
    "    RC = torch.clamp(RC, *pysical_param_bounds)\n",
    "    Rdson = torch.clamp(Rdson, *pysical_param_bounds) * 1e-1  # the Rdson is quite small\n",
    "    Rload = torch.clamp(Rload, *pysical_param_bounds) * 10  # Rload is in Ohm\n",
    "    Vin = torch.clamp(Vin, *pysical_param_bounds) * 10  # Vin is in V\n",
    "    Vf = torch.clamp(Vf, *pysical_param_bounds)  # Vf is in V\n",
    "    \n",
    "    # since the network favors small values, let's artificially increase the prediction scale\n",
    "    for param in [L, RL, C, RC, Rdson, Rload, Vin, Vf]:\n",
    "        param *= 10.0\n",
    "    return L, RL, C, RC, Rdson, Rload, Vin, Vf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9527b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JC28LS\\AppData\\Local\\Temp\\ipykernel_19180\\3022096116.py:55: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  X_denorm = X_norm * self.std + self.mean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "loss: 4.683e+68, lr: 0.000010, L: 0.000000 H, RL: 0.010516 Ohm, C: 0.000000 F\n",
      "RC: 0.012520 Ohm, Rdson: 0.009827 Ohm, Rload: 0.689042 Ohm, Vin: 1.000000 V, Vf: 0.040396 V\n",
      "Epoch 1001:\n",
      "loss: nan, lr: 0.000208, L: nan H, RL: nan Ohm, C: nan F\n",
      "RC: nan Ohm, Rdson: nan Ohm, Rload: nan Ohm, Vin: nan V, Vf: nan V\n",
      "Epoch 2001:\n",
      "loss: nan, lr: 0.000406, L: nan H, RL: nan Ohm, C: nan F\n",
      "RC: nan Ohm, Rdson: nan Ohm, Rload: nan Ohm, Vin: nan V, Vf: nan V\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m L, RL, C, RC, Rdson, Rload, Vin, Vf = torch.split(params_pred, \u001b[32m1\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# denormalize parameters and print the predicted values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m L, RL, C, RC, Rdson, Rload, Vin, Vf = \u001b[43mdenorm_physical_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRdson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVf\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# checkpoint\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss.item() < best_loss:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mdenorm_physical_params\u001b[39m\u001b[34m(L, RL, C, RC, Rdson, Rload, Vin, Vf)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03mDenormalize the physical parameters from their logarithmic form.\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03mThe parameters are expected to be in the logarithmic scale.\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m L = torch.clamp(L, *pysical_param_bounds)*\u001b[32m1e-6\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m RL = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mpysical_param_bounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m C = torch.clamp(C, *pysical_param_bounds) * \u001b[32m1e-6\u001b[39m  \u001b[38;5;66;03m# assume the network gets the uF value\u001b[39;00m\n\u001b[32m     29\u001b[39m RC = torch.clamp(RC, *pysical_param_bounds)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "Rload = Rload1 * np.ones_like(i_n)\n",
    "X_t = torch.tensor(X_norm, dtype=torch.float32)\n",
    "Rload_t = torch.tensor(Rload, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "device = \"cpu\"\n",
    "# --- Scheduler setup ---\n",
    "base_lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "cosine_amp = base_lr - min_lr\n",
    "cosine_floor = min_lr\n",
    "warmup_epochs = 5000\n",
    "total_epochs = int(50e4)\n",
    "\n",
    "\n",
    "# Custom amplitude decay controller\n",
    "plateau_counter = 0\n",
    "prev_loss = None\n",
    "plateau_patience = 6000\n",
    "cosine_shrink_factor = 0.7\n",
    "\n",
    "\n",
    "def get_cosine_lr(epoch: int, amp: float, period: int) -> float:\n",
    "    if epoch < warmup_epochs:\n",
    "        return cosine_floor + amp * (epoch + 1) / warmup_epochs\n",
    "    else:\n",
    "        progress = (epoch - warmup_epochs) / (period - warmup_epochs)\n",
    "        return cosine_floor + amp * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "\n",
    "# --- Model setup ---\n",
    "model = ParamEstimator(input_dim=6, hidden_layers=[32, 32])\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "scheduler_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.7, patience=3000\n",
    ")\n",
    "\n",
    "\n",
    "# --- Tracking ---\n",
    "loss_history = []\n",
    "param_history = []\n",
    "lr_history = []\n",
    "best_loss = float(\"inf\")\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    current_lr = get_cosine_lr(epoch, cosine_amp, total_epochs/10)\n",
    "    # Update learning rate manually\n",
    "    for g in optimizer.param_groups:\n",
    "        g[\"lr\"] = current_lr\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    params_pred = model(X_t)\n",
    "    x_n1_pred = physics_forward(X_t, params_pred, normalizer)\n",
    "    loss = compute_loss(X_t[:, :2], x_n1_pred)\n",
    "\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Track loss\n",
    "    loss_val = loss.item()\n",
    "\n",
    "    # Detect plateau\n",
    "    if prev_loss is not None and abs(loss_val - prev_loss) / (prev_loss + 1e-8) < 1e-4:\n",
    "        plateau_counter += 1\n",
    "    else:\n",
    "        plateau_counter = 0\n",
    "    prev_loss = loss_val\n",
    "\n",
    "    # Decay cosine amplitude if loss plateaus\n",
    "    if plateau_counter >= plateau_patience:\n",
    "        cosine_amp *= cosine_shrink_factor\n",
    "        plateau_counter = 0\n",
    "        print(f\"[Epoch {epoch}] Plateau detected. Shrinking cosine amplitude to {cosine_amp:.2e}\")\n",
    "\n",
    "    # get explicit predictions\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = torch.split(params_pred, 1, dim=1)\n",
    "\n",
    "    # denormalize parameters and print the predicted values\n",
    "    L, RL, C, RC, Rdson, Rload, Vin, Vf = denorm_physical_params(\n",
    "        L, RL, C, RC, Rdson, Rload, Vin, Vf\n",
    "    )\n",
    "\n",
    "    # checkpoint\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        best_state = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"physical_paramers\": {\n",
    "                \"L\": L.mean().item(),\n",
    "                \"RL\": RL.mean().item(),\n",
    "                \"C\": C.mean().item(),\n",
    "                \"RC\": RC.mean().item(),\n",
    "                \"Rdson\": Rdson.mean().item(),\n",
    "                \"Rload\": Rload.mean().item(),\n",
    "                \"Vin\": Vin.mean().item(),\n",
    "                \"Vf\": Vf.mean().item(),\n",
    "            },\n",
    "            \"loss\": best_loss,\n",
    "        }\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch + 1}:\")\n",
    "        print(\n",
    "            f\"loss: {loss.item():.3e}, lr: {optimizer.param_groups[0][\"lr\"]:.6f}, L: {L.mean().item():.6f} H, RL: {RL.mean().item():.6f} Ohm, C: {C.mean().item():.6f} F\"\n",
    "        )\n",
    "        print(\n",
    "            f\"RC: {RC.mean().item():.6f} Ohm, Rdson: {Rdson.mean().item():.6f} Ohm, Rload: {Rload.mean().item():.6f} Ohm, Vin: {Vin.mean().item():.6f} V, Vf: {Vf.mean().item():.6f} V\"\n",
    "        )\n",
    "\n",
    "    # adaptive schedule\n",
    "    scheduler_plateau.step(loss)\n",
    "\n",
    "    loss_history.append(loss_val)\n",
    "    param_history.append({\n",
    "        'L': L.mean().item(), 'RL': RL.mean().item(), 'C': C.mean().item(),\n",
    "        'RC': RC.mean().item(), 'Rdson': Rdson.mean().item(), 'Rload': Rload.mean().item(),\n",
    "        'Vin': Vin.mean().item(), 'Vf': Vf.mean().item()\n",
    "    })\n",
    "    # save the lr parameter\n",
    "    lr_history.append(optimizer.param_groups[0][\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a180582",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m] = {\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mbest_state\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mL\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRL\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mRL\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRC\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mRC\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRdson\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mRdson\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRload\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mRload\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mVin\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mVin\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mVf\u001b[39m\u001b[33m\"\u001b[39m: best_state[\u001b[33m\"\u001b[39m\u001b[33mphysical_paramers\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mVf\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     10\u001b[39m }\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# compare with nominal values\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtensor_to_average\u001b[39m(tensor: torch.Tensor) -> \u001b[38;5;28mfloat\u001b[39m:\n",
      "\u001b[31mNameError\u001b[39m: name 'best_state' is not defined"
     ]
    }
   ],
   "source": [
    "best_state[\"physical_paramers\"] = {\n",
    "    \"L\": best_state[\"physical_paramers\"][\"L\"],\n",
    "    \"RL\": best_state[\"physical_paramers\"][\"RL\"],\n",
    "    \"C\": best_state[\"physical_paramers\"][\"C\"],\n",
    "    \"RC\": best_state[\"physical_paramers\"][\"RC\"],\n",
    "    \"Rdson\": best_state[\"physical_paramers\"][\"Rdson\"],\n",
    "    \"Rload\": best_state[\"physical_paramers\"][\"Rload\"],\n",
    "    \"Vin\": best_state[\"physical_paramers\"][\"Vin\"],\n",
    "    \"Vf\": best_state[\"physical_paramers\"][\"Vf\"],\n",
    "}\n",
    "\n",
    "\n",
    "# compare with nominal values\n",
    "def tensor_to_average(tensor: torch.Tensor) -> float:\n",
    "    \"\"\"Convert a tensor to a float and return its average.\"\"\"\n",
    "    return tensor.mean().item() if isinstance(tensor, torch.Tensor) else float(tensor)\n",
    "\n",
    "print(\"Best state:\")\n",
    "print(f\"Epoch: {best_state['epoch']}\")\n",
    "print(f\"Loss: {best_state['loss']:.6e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EM+",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
